{"meta":{"title":"Hexo","subtitle":null,"description":null,"author":"John Doe","url":"http://yoursite.com","root":"/"},"pages":[],"posts":[{"title":"吴恩达机器学习作业Python实现(一)：线性回归","slug":"线性回归","date":"2019-07-28T16:11:25.633Z","updated":"2019-07-28T16:54:28.793Z","comments":true,"path":"2019/07/29/线性回归/","link":"","permalink":"http://yoursite.com/2019/07/29/线性回归/","excerpt":"","text":"单变量线性回归在本部分的练习中，您将使用一个变量实现线性回归，以预测食品卡车的利润：假设你是一家餐馆的首席执行官，正在考虑不同的城市开设一个新的分店。该连锁店已经在各个城市拥有卡车，而且你有来自城市的利润和人口数据。您希望使用这些数据来帮助您选择将哪个城市扩展到下一个城市。 123import numpy as npimport pandas as pdimport matplotlib.pyplot as plt 1.导入数据并查看：注意：开始任何任务之前，通过可视化来理解数据通常是有用的。在这个数据集中，只有两个属性（利润和人口），可以绘制散点图。许多其他问题是多维度的，例如下面的多变量线性回归的例子，就不能再二维图上画出来。 .describe()显示各统计值 123path = r'C:/Users/DH/Desktop/ex1data1.txt'data = pd.read_csv(path,names=['Population','Profit'])print(data.describe()) Population Profit count 97.000000 97.000000 mean 8.159800 5.839135 std 3.869884 5.510262 min 5.026900 -2.680700 25% 5.707700 1.986900 50% 6.589400 4.562300 75% 8.578100 7.046700 max 22.203000 24.147000绘制散点图：plt.scatter(x,y) 12345plt.scatter(data['Population'], data['Profit'])plt.xlabel('Population')plt.ylabel('Profit')#data.plot(kind='scatter', x='Population', y='Profit', figsize=(8,5))plt.show() 2.实现代价函数表达式，为所需各变量赋值 123def computeCost(X,Y,theta): inner = np.power((X*theta.T)-Y,2) return np.sum(inner)/(2*len(X)) 数据集插入一列方便之后进行向量运算，作为$x_0$,值均为1： 12data.insert(0,'Ones',1)print(data.head()) Ones Population Profit 0 1 6.1101 17.5920 1 1 5.5277 9.1302 2 1 8.5186 13.6620 3 1 7.0032 11.8540 4 1 5.8598 6.8233对表达式中自变量X，因变量Y，未知参数θ初始化（1）data.shape[1]表示列数，data.shape[0]表示行数。（2）data.iloc[]函数通过行号来取行数据 data.iloc[:,cols-1:cols]提取最后一列数据，从0开始计数 1234#set X(training data) and Y(target varible)cols = data.shape[1] #列数X = data.iloc[:,0:cols-1] Y = data.iloc[:,cols-1:cols] #取最后一列，即目标向量 将X,Y转换为矩阵，初始化theta为一个（1,2）矩阵：转换为矩阵是为了方便矩阵运算，对于矩阵matrix，即为点乘，而对于数组array，为对应位置元素相乘，若要点乘，则需要用到np.dot(X1,X2) 123X = np.matrix(X.values)Y = np.matrix(Y.values)theta =np.matrix([0,0]) 3.实现梯度下降函数 12345678910111213141516def gradientDescent(X, Y, theta, alpha, epoch): temp = np.matrix(np.zeros(theta.shape)) # 初始化一个临时矩阵(1, 2) cost = np.zeros(epoch) # 初始化一个ndarray，包含每次epoch的cost m = X.shape[0] # m为总的样本数 #利用向量化一步求解 for i in range(epoch): temp = theta - (alpha / m) * (X * theta.T - Y).T * X theta = temp cost[i] = computeCost(X,Y,theta) #得到每次迭代代价函数的值 return theta,cost#初始化学习率α和要进行迭代的次数alpha = 0.01epoch = 1000#现在让我们运行梯度下降算法来将我们的参数θ适合于训练集final_theta,cost = gradientDescent(X,Y,theta,alpha,epoch) 4.绘制线性模型，直观看出拟合（1）np.linspace()在指定的间隔内返回均匀间隔的数字。 1234567891011x = np.linspace(data.Population.min(),data.Population.max(),100)f = final_theta[0,0] + (final_theta[0,1] * x) fig, ax = plt.subplots(figsize=(6,4))ax.plot(x, f, 'r', label='Prediction')ax.scatter(data['Population'], data.Profit, label='Traning Data')ax.legend(loc=2) # 2表示在左上角ax.set_xlabel('Population')ax.set_ylabel('Profit')ax.set_title('Predicted Profit vs. Population Size')plt.show() 由于梯度方程式函数也在每个训练迭代中输出一个代价的向量，所以我们也可以绘制。 123456fig,ax = plt.subplots(figsize = (8,4))ax.plot(np.arange(epoch),cost,'r') #np.arange()返回等差数组ax.set_xlabel('Iterations')ax.set_ylabel('Cost')ax.set_title('Error vs. Training Epoch')plt.show() 正规方程法1234def normalEqn(X, y): theta = np.linalg.inv(X.T*X)*X.T*y#X.T*X等价于X.T.dot(X) return theta.Tfinal_theta2 = normalEqn(X,Y) 打印两种方法的得到的参数值： 1print(final_theta,'\\n',final_theta2) [[-3.24140214 1.1272942 ]] [[-3.89578088 1.19303364]]","categories":[],"tags":[]},{"title":"Hello World","slug":"hello-world","date":"2019-07-28T09:29:14.049Z","updated":"2019-07-28T15:45:33.951Z","comments":true,"path":"2019/07/28/hello-world/","link":"","permalink":"http://yoursite.com/2019/07/28/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}]}
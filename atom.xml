<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Hexo</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://hiworldalice.github.io/"/>
  <updated>2019-07-30T05:42:03.977Z</updated>
  <id>https://hiworldalice.github.io/</id>
  
  <author>
    <name>Tnut</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>吴恩达机器学习作业Python实现(一)：线性回归</title>
    <link href="https://hiworldalice.github.io/2019/07/29/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"/>
    <id>https://hiworldalice.github.io/2019/07/29/线性回归/</id>
    <published>2019-07-28T19:20:34.000Z</published>
    <updated>2019-07-30T05:42:03.977Z</updated>
    
    <content type="html"><![CDATA[<h2 id="单变量线性回归"><a href="#单变量线性回归" class="headerlink" title="单变量线性回归"></a>单变量线性回归</h2><p>在本部分的练习中，您将使用一个变量实现线性回归，以预测食品卡车的利润：<br>假设你是一家餐馆的首席执行官，正在考虑不同的城市开设一个新的分店。该连锁店已经在各个城市拥有卡车，而且你有来自城市的利润和人口数据。<br>您希望使用这些数据来帮助您选择将哪个城市扩展到下一个城市。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br></pre></td></tr></table></figure><h3 id="导入数据集并查看："><a href="#导入数据集并查看：" class="headerlink" title="导入数据集并查看："></a>导入数据集并查看：</h3><p>注意：开始任何任务之前，通过可视化来理解数据通常是有用的。在这个数据集中，只有两个属性（利润和人口），可以绘制散点图。许多其他问题是多维度的，例如下面的多变量线性回归的例子，就不能再二维图上画出来。</p><p>.describe()显示各统计值</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">path = <span class="string">r'C:/Users/DH/Desktop/ex1data1.txt'</span></span><br><span class="line">data = pd.read_csv(path,names=[<span class="string">'Population'</span>,<span class="string">'Profit'</span>])</span><br><span class="line">print(data.describe())</span><br></pre></td></tr></table></figure><pre><code>       Population     Profitcount   97.000000  97.000000mean     8.159800   5.839135std      3.869884   5.510262min      5.026900  -2.68070025%      5.707700   1.98690050%      6.589400   4.56230075%      8.578100   7.046700max     22.203000  24.147000</code></pre><p>绘制散点图：<br>plt.scatter(x,y)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">plt.scatter(data[<span class="string">'Population'</span>], data[<span class="string">'Profit'</span>])</span><br><span class="line">plt.xlabel(<span class="string">'Population'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'Profit'</span>)</span><br><span class="line"><span class="comment">#data.plot(kind='scatter', x='Population', y='Profit', figsize=(8,5))</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/images/output_6_0.png" alt="png"></p><h3 id="实现代价函数表达式，为所需各变量赋值"><a href="#实现代价函数表达式，为所需各变量赋值" class="headerlink" title="实现代价函数表达式，为所需各变量赋值"></a>实现代价函数表达式，为所需各变量赋值</h3><p>代价函数表达式：<script type="math/tex">J(\theta_0,\theta_1,...,\theta_n)=\frac{\sum_{i=1}^m{({h_\theta(x^{(i)})}-y^{(i)})}^2}{2m}</script>其中<script type="math/tex">h_\theta=\theta^TX=\theta_0+\theta_1x_1+\theta_2x_2+...+\theta_nx_n</script></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">computeCost</span><span class="params">(X,Y,theta)</span>:</span></span><br><span class="line">    inner = np.power((X*theta.T)-Y,<span class="number">2</span>)</span><br><span class="line">    <span class="keyword">return</span> np.sum(inner)/(<span class="number">2</span>*len(X))</span><br></pre></td></tr></table></figure><p>数据集插入一列方便之后进行向量运算，作为$x_0$,值均为1：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">data.insert(<span class="number">0</span>,<span class="string">'Ones'</span>,<span class="number">1</span>)</span><br><span class="line">print(data.head())</span><br></pre></td></tr></table></figure><pre><code>   Ones  Population   Profit0     1      6.1101  17.59201     1      5.5277   9.13022     1      8.5186  13.66203     1      7.0032  11.85404     1      5.8598   6.8233</code></pre><p>对表达式中自变量X，因变量Y，未知参数θ初始化<br>（1）data.shape[1]表示列数，data.shape[0]表示行数。<br>（2）data.iloc[]函数通过行号来取行数据<br>     data.iloc[:,cols-1:cols]提取最后一列数据，从0开始计数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#set X(training data) and Y(target varible)</span></span><br><span class="line">cols = data.shape[<span class="number">1</span>] <span class="comment">#列数</span></span><br><span class="line">X = data.iloc[:,<span class="number">0</span>:cols<span class="number">-1</span>] </span><br><span class="line">Y = data.iloc[:,cols<span class="number">-1</span>:cols] <span class="comment">#取最后一列，即目标向量</span></span><br></pre></td></tr></table></figure><p>将X,Y转换为矩阵，初始化theta为一个（1,2）矩阵：<br>转换为矩阵是为了方便矩阵运算，对于矩阵matrix，<em>即为点乘，而对于数组array，</em>为对应位置元素相乘，若要点乘，则需要用到np.dot(X1,X2)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">X = np.matrix(X.values)</span><br><span class="line">Y = np.matrix(Y.values)</span><br><span class="line">theta =np.matrix([<span class="number">0</span>,<span class="number">0</span>])</span><br></pre></td></tr></table></figure><h3 id="实现梯度下降函数"><a href="#实现梯度下降函数" class="headerlink" title="实现梯度下降函数"></a>实现梯度下降函数</h3><p>bathch gradient decent(批量梯度下降)</p><script type="math/tex; mode=display">\theta_j:=\theta_j-\alpha\frac{\partial}{partial\theta_j}J(\theta)</script><script type="math/tex; mode=display">\theta_j:=\theta_j-\alpha\frac{\sum_{i=1}^m{({h_\theta(x^{(i)})}-y^{(i)})}{x_j}^{(i)}}{m}</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gradientDescent</span><span class="params">(X, Y, theta, alpha, epoch)</span>:</span></span><br><span class="line">    temp = np.matrix(np.zeros(theta.shape))  <span class="comment"># 初始化一个临时矩阵(1, 2)</span></span><br><span class="line">    cost = np.zeros(epoch)                   <span class="comment"># 初始化一个ndarray，包含每次epoch的cost</span></span><br><span class="line">    m = X.shape[<span class="number">0</span>]                           <span class="comment"># m为总的样本数</span></span><br><span class="line">    <span class="comment">#利用向量化一步求解</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(epoch):</span><br><span class="line">        temp = theta - (alpha / m) * (X * theta.T - Y).T * X</span><br><span class="line">        theta = temp</span><br><span class="line">        cost[i] = computeCost(X,Y,theta) <span class="comment">#得到每次迭代代价函数的值</span></span><br><span class="line">    <span class="keyword">return</span> theta,cost</span><br><span class="line"></span><br><span class="line"><span class="comment">#初始化学习率α和要进行迭代的次数</span></span><br><span class="line">alpha = <span class="number">0.01</span></span><br><span class="line">epoch = <span class="number">1000</span></span><br><span class="line"><span class="comment">#现在让我们运行梯度下降算法来将我们的参数θ适合于训练集</span></span><br><span class="line">final_theta,cost = gradientDescent(X,Y,theta,alpha,epoch)</span><br></pre></td></tr></table></figure><h3 id="绘制线性模型，直观看出拟合"><a href="#绘制线性模型，直观看出拟合" class="headerlink" title="绘制线性模型，直观看出拟合"></a>绘制线性模型，直观看出拟合</h3><p>（1）np.linspace()在指定的间隔内返回均匀间隔的数字。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">x = np.linspace(data.Population.min(),data.Population.max(),<span class="number">100</span>)</span><br><span class="line">f = final_theta[<span class="number">0</span>,<span class="number">0</span>] + (final_theta[<span class="number">0</span>,<span class="number">1</span>] * x) </span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots(figsize=(<span class="number">6</span>,<span class="number">4</span>))</span><br><span class="line">ax.plot(x, f, <span class="string">'r'</span>, label=<span class="string">'Prediction'</span>)</span><br><span class="line">ax.scatter(data[<span class="string">'Population'</span>], data.Profit, label=<span class="string">'Traning Data'</span>)</span><br><span class="line">ax.legend(loc=<span class="number">2</span>)  <span class="comment"># 2表示在左上角</span></span><br><span class="line">ax.set_xlabel(<span class="string">'Population'</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">'Profit'</span>)</span><br><span class="line">ax.set_title(<span class="string">'Predicted Profit vs. Population Size'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/images/output_18_0.png" alt="png"></p><p>由于梯度方程式函数也在每个训练迭代中输出一个代价的向量，所以我们也可以绘制。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">fig,ax = plt.subplots(figsize = (<span class="number">8</span>,<span class="number">4</span>))</span><br><span class="line">ax.plot(np.arange(epoch),cost,<span class="string">'r'</span>) <span class="comment">#np.arange()返回等差数组</span></span><br><span class="line">ax.set_xlabel(<span class="string">'Iterations'</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">'Cost'</span>)</span><br><span class="line">ax.set_title(<span class="string">'Error vs. Training Epoch'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/images/output_20_0.png" alt="png"></p><h4 id="正规方程法"><a href="#正规方程法" class="headerlink" title="正规方程法"></a>正规方程法</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">normalEqn</span><span class="params">(X, y)</span>:</span></span><br><span class="line">    theta = np.linalg.inv(X.T*X)*X.T*y<span class="comment">#X.T*X等价于X.T.dot(X)</span></span><br><span class="line">    <span class="keyword">return</span> theta.T</span><br><span class="line">final_theta2 = normalEqn(X,Y)</span><br></pre></td></tr></table></figure><p>打印两种方法的得到的参数值：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(final_theta,<span class="string">'\n'</span>,final_theta2)</span><br></pre></td></tr></table></figure><pre><code>[[-3.24140214  1.1272942 ]]  [[-3.89578088  1.19303364]]</code></pre><h2 id="多变量线性回归"><a href="#多变量线性回归" class="headerlink" title="多变量线性回归"></a>多变量线性回归</h2><p>练习1还包括一个房屋价格数据集，其中有2个变量（房子的大小，卧室的数量）和目标（房子的价格）。 我们使用我们已经应用的技术来分析数据集。</p><h3 id="导入数据集并查看"><a href="#导入数据集并查看" class="headerlink" title="导入数据集并查看"></a>导入数据集并查看</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">path = <span class="string">r'C:/Users/DH/Desktop/ex1data2.txt'</span></span><br><span class="line">data = pd.read_csv(path,names = [<span class="string">'sizes'</span>,<span class="string">'rooms'</span>,<span class="string">'prices'</span>])</span><br><span class="line">print(data.head())</span><br></pre></td></tr></table></figure><pre><code>   sizes  rooms  prices0   2104      3  3999001   1600      3  3299002   2400      3  3690003   1416      2  2320004   3000      4  539900</code></pre><p>对于此任务，我们添加了另一个预处理步骤：特征缩放，否则以$\theta_1$，$\theta_2$两个参数分别为横纵坐标，绘制代价函数的等高线图能，看出图像会显得很扁，梯度下降算法需要非常多次的迭代才能收敛。<br>解决的方法是尝试将所有特征的尺度都尽量缩放到-1 到 1 之间:</p><script type="math/tex; mode=display">\frac{x_n-\mu_n}{s_n}</script><p>其中$\mu_n$是平均值，$s_n$是标准差。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">data[<span class="string">'sizes'</span>] = (data[<span class="string">'sizes'</span>] - data[<span class="string">'sizes'</span>].mean())/data[<span class="string">'sizes'</span>].std()</span><br><span class="line">data[<span class="string">'rooms'</span>] = (data[<span class="string">'rooms'</span>] - data[<span class="string">'rooms'</span>].mean())/data[<span class="string">'rooms'</span>].std()</span><br><span class="line">data[<span class="string">'prices'</span>] = (data[<span class="string">'prices'</span>] - data[<span class="string">'prices'</span>].mean())/data[<span class="string">'prices'</span>].std()</span><br><span class="line">print(data.head())</span><br></pre></td></tr></table></figure><pre><code>      sizes     rooms    prices0  0.130010 -0.223675  0.4757471 -0.504190 -0.223675 -0.0840742  0.502476 -0.223675  0.2286263 -0.735723 -1.537767 -0.8670254  1.257476  1.090417  1.595389</code></pre><h3 id="实现代价函数表达式，为所需各变量赋值-1"><a href="#实现代价函数表达式，为所需各变量赋值-1" class="headerlink" title="实现代价函数表达式，为所需各变量赋值"></a>实现代价函数表达式，为所需各变量赋值</h3><p>此步骤除代价函数表达式与单变量线性回归有所不同，参数个数增加外，处理方式与单变量线性回归相同。<br>代价函数表达式：<script type="math/tex">J(\theta_0,\theta_1,...,\theta_n)=\frac{\sum_{i=1}^m{({h_\theta(x^{(i)})}-y^{(i)})}^2}{2m}</script>其中<script type="math/tex">h_\theta=\theta^TX=\theta_0+\theta_1x_1+\theta_2x_2+...+\theta_nx_n</script></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">theta = np.matrix(np.zeros(<span class="number">3</span>))</span><br><span class="line"><span class="comment">#插入一列，作为x0,值为1</span></span><br><span class="line">data.insert(<span class="number">0</span>,<span class="string">'ones'</span>,<span class="number">1</span>)</span><br><span class="line">cols = data.shape[<span class="number">1</span>]</span><br><span class="line"><span class="comment">#X = np.matrix(data[:2]) 仅选取前两行</span></span><br><span class="line">X = np.matrix(data.iloc[:,<span class="number">0</span>:cols<span class="number">-1</span>])</span><br><span class="line">Y = np.matrix(data.iloc[:,cols<span class="number">-1</span>:cols])</span><br><span class="line"><span class="comment">#代价函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">computeCost</span><span class="params">(X,Y,theta)</span>:</span></span><br><span class="line">    m = X.shape[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">return</span> np.sum(np.power((X*theta.T) - Y,<span class="number">2</span>))/(<span class="number">2</span>*m)</span><br></pre></td></tr></table></figure><h3 id="实现梯度下降算法"><a href="#实现梯度下降算法" class="headerlink" title="实现梯度下降算法"></a>实现梯度下降算法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#梯度下降</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gradientDescent</span><span class="params">(X,Y,theta,alpha,epoch)</span>:</span></span><br><span class="line">    m = X.shape[<span class="number">0</span>]</span><br><span class="line">    cost = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(epoch):</span><br><span class="line">        theta = theta - alpha/m*(X*theta.T - Y).T*X</span><br><span class="line">        cost.append(computeCost(X,Y,theta))       <span class="comment">#列表添加元素</span></span><br><span class="line">    <span class="keyword">return</span> theta,cost</span><br><span class="line"></span><br><span class="line">alpha = <span class="number">0.01</span></span><br><span class="line">epoch = <span class="number">1000</span></span><br><span class="line">final_theta,cost = gradientDescent(X,Y,theta,alpha,epoch)</span><br><span class="line">final_cost = computeCost(X,Y,final_theta)</span><br><span class="line">print(final_cost)</span><br></pre></td></tr></table></figure><pre><code>0.13070336960771892</code></pre><h3 id="画图查看训练过程"><a href="#画图查看训练过程" class="headerlink" title="画图查看训练过程"></a>画图查看训练过程</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#画图查看训练过程</span></span><br><span class="line">fig,ax = plt.subplots(figsize=(<span class="number">12</span>,<span class="number">8</span>))</span><br><span class="line">ax.plot(np.arange(epoch),cost,<span class="string">'r'</span>)</span><br><span class="line">ax.set_xlabel(<span class="string">'Iterations'</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">'Cost'</span>)</span><br><span class="line">ax.set_title(<span class="string">'Error vs. Training Epoch'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/images/output_34_0.png" alt="png"></p><h4 id="正规方程法-1"><a href="#正规方程法-1" class="headerlink" title="正规方程法"></a>正规方程法</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#正规方程法</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">normalEqn</span><span class="params">(X, y)</span>:</span></span><br><span class="line">    theta = np.linalg.inv(X.T*X)*X.T*y<span class="comment">#X.T*X等价于X.T.dot(X)</span></span><br><span class="line">    <span class="keyword">return</span> theta.T</span><br><span class="line">final_theta2 = normalEqn(X,Y)</span><br></pre></td></tr></table></figure><p>打印两种方法的得到的参数值：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(final_theta,<span class="string">'\n'</span>,final_theta2)</span><br></pre></td></tr></table></figure><pre><code>[[-1.11113782e-16  8.78503652e-01 -4.69166570e-02]]  [[-1.17961196e-16  8.84765988e-01 -5.31788197e-02]]</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;单变量线性回归&quot;&gt;&lt;a href=&quot;#单变量线性回归&quot; class=&quot;headerlink&quot; title=&quot;单变量线性回归&quot;&gt;&lt;/a&gt;单变量线性回归&lt;/h2&gt;&lt;p&gt;在本部分的练习中，您将使用一个变量实现线性回归，以预测食品卡车的利润：&lt;br&gt;假设你是一家餐馆的首席
      
    
    </summary>
    
      <category term="python" scheme="https://hiworldalice.github.io/categories/python/"/>
    
    
      <category term="机器学习" scheme="https://hiworldalice.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="https://hiworldalice.github.io/2019/07/28/hello-world/"/>
    <id>https://hiworldalice.github.io/2019/07/28/hello-world/</id>
    <published>2019-07-28T09:29:14.049Z</published>
    <updated>2019-07-28T15:45:33.951Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.
      
    
    </summary>
    
    
  </entry>
  
</feed>
